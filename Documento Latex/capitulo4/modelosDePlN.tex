Antes de la adopción generalizada de modelos de aprendizaje profundo (Deep Learning Models), el procesamiento de lenguaje natural se basaba en técnicas como la codificación one-hot, que asignaba a cada palabra un vector binario de alta dimensión con un único valor de uno y ceros en las demás posiciones. Sin embargo, este enfoque no capturaba relaciones semánticas entre palabras y resultaba ineficiente para tareas complejas de PLN.
\\
\\
El Procesamiento de Lenguaje Natural ha experimentado avances significativos en la última década, impulsado por el desarrollo de modelos de aprendizaje profundo (Deep Learning). Estos avances han transformado la forma en que las máquinas comprenden y generan lenguaje humano, permitiendo la creación de aplicaciones orientadas a brindar apoyo en distintas áreas. Se han desarrollado herramientas que facilitan la traducción automática, los asistentes virtuales, el análisis de sentimientos, la corrección gramatical, la clasificación de textos, entre muchas otras. Estas aplicaciones han mejorado la eficiencia y accesibilidad en sectores como la educación, la salud, el comercio, la atención al cliente y la investigación científica.
\\
\\
El desarrollo de representaciones distribuidas de palabras, también conocidas como word embeddings, permitió representar palabras como vectores densos en un espacio continuo de menor dimensión. Estas representaciones capturan similitudes semánticas y sintácticas entre palabras, facilitando tareas como la clasificación de texto, la traducción automática y la respuesta a preguntas.
\\
\\
Hoy en dia se tienen diferentes formas de aplicar algoritmos y/o modelos de PLN, como lo son Word2Vec, GloVe, Transformadores, GPT, BERT, RoBERTa etc... A lo que nos planteamos ¿que arquitectura y modelos podemos utilizar para el desarrollo del prototipo?

\input{capitulo4/busquedaModelos}